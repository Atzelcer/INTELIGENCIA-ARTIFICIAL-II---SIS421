{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905da27d",
   "metadata": {},
   "source": [
    "\n",
    "# Cuadernillo: EfficientNet (Teor√≠a + Implementaci√≥n en PyTorch)\n",
    "\n",
    "Este cuadernillo combina la explicaci√≥n te√≥rica de EfficientNet con una implementaci√≥n educativa en PyTorch de la versi√≥n B0 (modelo base).\n",
    "\n",
    "## Contenido:\n",
    "- Introducci√≥n a EfficientNet y el escalado compuesto.\n",
    "- Arquitectura de EfficientNet-B0.\n",
    "- Implementaci√≥n desde cero del bloque MBConv con Squeeze-and-Excitation (SE).\n",
    "- Construcci√≥n de EfficientNet-B0 mini.\n",
    "- Ejemplo de inferencia.\n",
    "- Ejemplo de fine-tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcfd922",
   "metadata": {},
   "source": [
    "## 1. Introducci√≥n a EfficientNet\n",
    "\n",
    "EfficientNet es una familia de redes neuronales convolucionales que introduce el concepto de **escalado compuesto** para mejorar el rendimiento y la eficiencia. La idea es escalar de forma balanceada tres dimensiones de la red:\n",
    "\n",
    "- **Profundidad (d):** N√∫mero de capas.\n",
    "- **Anchura (w):** N√∫mero de canales en cada capa.\n",
    "- **Resoluci√≥n (r):** Tama√±o de la imagen de entrada.\n",
    "\n",
    "### üî¨ Escalado Compuesto\n",
    "\n",
    "El escalado se controla con un factor œÜ (phi) y tres coeficientes Œ±, Œ≤, Œ≥:\n",
    "\n",
    "```\n",
    "depth = Œ±^œÜ\n",
    "width = Œ≤^œÜ  \n",
    "resolution = Œ≥^œÜ\n",
    "```\n",
    "\n",
    "**Restricci√≥n:** Œ± ¬∑ Œ≤¬≤ ¬∑ Œ≥¬≤ ‚âà 2, donde Œ± ‚â• 1, Œ≤ ‚â• 1, Œ≥ ‚â• 1\n",
    "\n",
    "### üéØ Ventajas de EfficientNet:\n",
    "\n",
    "1. **Eficiencia computacional**: Mejor accuracy con menos par√°metros\n",
    "2. **Escalado balanceado**: No solo aumenta una dimensi√≥n\n",
    "3. **Transferible**: Funciona bien en diferentes tareas\n",
    "4. **Arquitectura optimizada**: Basada en Neural Architecture Search (NAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f751228",
   "metadata": {},
   "source": [
    "## Arquitectura de EfficientNet\n",
    "\n",
    "La siguiente imagen muestra la arquitectura y funcionamiento de EfficientNet:\n",
    "\n",
    "![EfficientNet Architecture](IMAGE.png)\n",
    "\n",
    "*Figura: Arquitectura y escalado compuesto de EfficientNet mostrando c√≥mo se balancean las dimensiones de profundidad, anchura y resoluci√≥n.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1da8b2",
   "metadata": {},
   "source": [
    "## üìä Funcionamiento Detallado del Modelo EfficientNet\n",
    "\n",
    "### üèóÔ∏è **Arquitectura General**\n",
    "\n",
    "EfficientNet sigue esta estructura principal:\n",
    "\n",
    "```\n",
    "Input Image ‚Üí Stem ‚Üí MBConv Blocks ‚Üí Head ‚Üí Output\n",
    "```\n",
    "\n",
    "### üîç **1. Stem (Inicio)**\n",
    "- **Funci√≥n**: Preprocesamiento inicial de la imagen\n",
    "- **Operaci√≥n**: Convoluci√≥n 3x3 con stride=2\n",
    "- **Salida**: Reduce resoluci√≥n a la mitad, extrae caracter√≠sticas b√°sicas\n",
    "- **Canales**: RGB (3) ‚Üí 32 caracter√≠sticas\n",
    "\n",
    "### üß± **2. Bloques MBConv (Coraz√≥n del modelo)**\n",
    "\n",
    "Los bloques MBConv son la innovaci√≥n clave. Cada bloque realiza:\n",
    "\n",
    "#### **Paso 1: Expansi√≥n (1x1 Conv)**\n",
    "```python\n",
    "# Si expand_ratio > 1\n",
    "channels: in_ch ‚Üí in_ch * expand_ratio\n",
    "# Ejemplo: 32 ‚Üí 192 canales (expand_ratio=6)\n",
    "```\n",
    "\n",
    "#### **Paso 2: Depthwise Convolution**\n",
    "```python\n",
    "# Convoluci√≥n por grupos (cada canal por separado)\n",
    "- Reduce par√°metros significativamente\n",
    "- Captura patrones espaciales por canal\n",
    "- Kernel: 3x3 o 5x5\n",
    "```\n",
    "\n",
    "#### **Paso 3: Squeeze-and-Excitation (SE)**\n",
    "```python\n",
    "# Recalibraci√≥n de canales\n",
    "Global Average Pool ‚Üí FC ‚Üí ReLU ‚Üí FC ‚Üí Sigmoid ‚Üí Multiply\n",
    "```\n",
    "\n",
    "#### **Paso 4: Proyecci√≥n (1x1 Conv)**\n",
    "```python\n",
    "# Reducci√≥n de canales\n",
    "channels: expanded ‚Üí out_ch\n",
    "# Ejemplo: 192 ‚Üí 40 canales\n",
    "```\n",
    "\n",
    "#### **Paso 5: Skip Connection**\n",
    "```python\n",
    "if stride == 1 and in_ch == out_ch:\n",
    "    output = projection + input  # Residual connection\n",
    "```\n",
    "\n",
    "### üéØ **3. Head (Final)**\n",
    "- **Global Average Pooling**: Convierte feature maps a vector\n",
    "- **Dropout**: Regularizaci√≥n para evitar overfitting  \n",
    "- **Linear**: Clasificaci√≥n final (1000 clases en ImageNet)\n",
    "\n",
    "### ‚ö° **Flujo de Datos Completo**\n",
    "\n",
    "```\n",
    "Imagen (224x224x3)\n",
    "    ‚Üì Stem Conv3x3\n",
    "Feature Maps (112x112x32)\n",
    "    ‚Üì MBConv Stage 1 (16 canales)\n",
    "Feature Maps (112x112x16)\n",
    "    ‚Üì MBConv Stage 2 (24 canales)\n",
    "Feature Maps (56x56x24)\n",
    "    ‚Üì MBConv Stage 3 (40 canales)\n",
    "Feature Maps (28x28x40)\n",
    "    ‚Üì MBConv Stage 4 (80 canales)\n",
    "Feature Maps (14x14x80)\n",
    "    ‚Üì MBConv Stage 5 (112 canales)\n",
    "Feature Maps (14x14x112)\n",
    "    ‚Üì MBConv Stage 6 (192 canales)\n",
    "Feature Maps (7x7x192)\n",
    "    ‚Üì MBConv Stage 7 (320 canales)\n",
    "Feature Maps (7x7x320)\n",
    "    ‚Üì Head Conv1x1\n",
    "Feature Maps (7x7x1280)\n",
    "    ‚Üì Global Average Pool\n",
    "Vector (1280)\n",
    "    ‚Üì Dropout + Linear\n",
    "Logits (1000 clases)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f9aa8",
   "metadata": {},
   "source": [
    "## 2. Bloque Squeeze-and-Excitation (SE) - Explicaci√≥n Detallada\n",
    "\n",
    "### üß† **¬øQu√© problema resuelve SE?**\n",
    "\n",
    "Las redes convolucionales tradicionales tratan todos los canales por igual. Sin embargo, **algunos canales contienen informaci√≥n m√°s relevante que otros**. El bloque SE aprende a **recalibrar autom√°ticamente** la importancia de cada canal.\n",
    "\n",
    "### ‚öôÔ∏è **Funcionamiento paso a paso:**\n",
    "\n",
    "#### **Paso 1: Squeeze (Compresi√≥n) üóúÔ∏è**\n",
    "```python\n",
    "# Global Average Pooling\n",
    "input: (Batch, Channels, Height, Width)\n",
    "output: (Batch, Channels, 1, 1)\n",
    "```\n",
    "- **Funci√≥n**: Convierte cada mapa de caracter√≠sticas 2D en un √∫nico valor\n",
    "- **Resultado**: Captura la \"esencia\" global de cada canal\n",
    "- **Matem√°ticamente**: `z_c = (1/H*W) * Œ£(x_c(i,j))`\n",
    "\n",
    "#### **Paso 2: Excitation (Activaci√≥n) ‚ö°**\n",
    "```python\n",
    "# Dos capas completamente conectadas\n",
    "FC1: channels ‚Üí channels//reduction  # Compresi√≥n\n",
    "ReLU: Activaci√≥n no lineal\n",
    "FC2: channels//reduction ‚Üí channels   # Expansi√≥n  \n",
    "Sigmoid: Normalizaci√≥n [0,1]\n",
    "```\n",
    "- **Funci√≥n**: Aprende las interdependencias entre canales\n",
    "- **Reduction**: T√≠picamente 4 o 16 (reduce par√°metros)\n",
    "- **Sigmoid**: Asegura que los pesos est√©n entre 0 y 1\n",
    "\n",
    "#### **Paso 3: Scale (Reescalado) üìè**\n",
    "```python\n",
    "# Multiplicaci√≥n elemento por elemento\n",
    "output = input * se_weights.unsqueeze(-1).unsqueeze(-1)\n",
    "```\n",
    "- **Funci√≥n**: Aplica los pesos aprendidos a cada canal\n",
    "- **Resultado**: Canales importantes se amplifican, irrelevantes se aten√∫an\n",
    "\n",
    "### üéØ **Ejemplo Pr√°ctico:**\n",
    "Si tenemos una imagen de un gato:\n",
    "- **Canales de bordes**: Peso alto (importante para detectar forma)\n",
    "- **Canales de textura**: Peso medio (√∫til para pelaje)\n",
    "- **Canales de ruido**: Peso bajo (informaci√≥n irrelevante)\n",
    "\n",
    "### üìà **Beneficios:**\n",
    "1. **Mejora accuracy** sin costo computacional significativo\n",
    "2. **Atenci√≥n autom√°tica** en caracter√≠sticas relevantes  \n",
    "3. **F√°cil integraci√≥n** en cualquier arquitectura CNN\n",
    "4. **Pocos par√°metros adicionales** (~2% del total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bac894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        hidden = max(1, channels // reduction)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, hidden, kernel_size=1),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(hidden, channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        w = self.pool(x)\n",
    "        w = self.fc(w)\n",
    "        return x * w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34fce9",
   "metadata": {},
   "source": [
    "## 3. Bloque MBConv (Mobile Inverted Bottleneck) - An√°lisis Completo\n",
    "\n",
    "### üèóÔ∏è **Filosof√≠a del Dise√±o**\n",
    "\n",
    "El bloque MBConv invierte la filosof√≠a tradicional de los bottlenecks:\n",
    "- **Bottleneck tradicional**: Ancho ‚Üí Estrecho ‚Üí Ancho\n",
    "- **Inverted Bottleneck**: Estrecho ‚Üí Ancho ‚Üí Estrecho\n",
    "\n",
    "### üîÑ **Arquitectura Detallada:**\n",
    "\n",
    "```\n",
    "Input (low-dim) ‚Üí Expand (high-dim) ‚Üí Filter ‚Üí Compress (low-dim) ‚Üí Output\n",
    "```\n",
    "\n",
    "#### **üöÄ Ventaja 1: Expansi√≥n**\n",
    "```python\n",
    "# Expansi√≥n 1x1 (si expand_ratio > 1)\n",
    "if expand_ratio != 1:\n",
    "    channels: in_ch ‚Üí in_ch * expand_ratio\n",
    "```\n",
    "- **Por qu√©**: Las convoluciones depthwise funcionan mejor con m√°s canales\n",
    "- **Ejemplo**: 32 canales ‚Üí 192 canales (expand_ratio=6)\n",
    "- **Beneficio**: M√°s \"espacio\" para aprender caracter√≠sticas complejas\n",
    "\n",
    "#### **üéØ Ventaja 2: Depthwise Convolution**\n",
    "```python\n",
    "# Convoluci√≥n por grupos (cada canal independiente)\n",
    "groups = input_channels  # Cada canal se procesa por separado\n",
    "```\n",
    "\n",
    "**Comparaci√≥n de par√°metros:**\n",
    "```python\n",
    "# Convoluci√≥n tradicional 3x3:\n",
    "params_traditional = in_ch * out_ch * 3 * 3\n",
    "# Ejemplo: 192 * 192 * 9 = 331,776 par√°metros\n",
    "\n",
    "# Depthwise + Pointwise:\n",
    "params_depthwise = in_ch * 3 * 3 + in_ch * out_ch\n",
    "# Ejemplo: 192 * 9 + 192 * 32 = 1,728 + 6,144 = 7,872 par√°metros\n",
    "# ¬°42x menos par√°metros!\n",
    "```\n",
    "\n",
    "#### **üß† Ventaja 3: Informaci√≥n Preservada**\n",
    "La conexi√≥n residual preserva informaci√≥n:\n",
    "```python\n",
    "if stride == 1 and in_ch == out_ch:\n",
    "    output = processed_input + input  # Skip connection\n",
    "```\n",
    "\n",
    "### üìä **Flujo Completo de un MBConv:**\n",
    "\n",
    "```python\n",
    "# Entrada: (B, 32, 56, 56)\n",
    "#     ‚Üì Expand 1x1 (32‚Üí192)\n",
    "# (B, 192, 56, 56)\n",
    "#     ‚Üì Depthwise 3x3\n",
    "# (B, 192, 28, 28)  # Si stride=2\n",
    "#     ‚Üì SE Module (recalibraci√≥n)\n",
    "# (B, 192, 28, 28)\n",
    "#     ‚Üì Project 1x1 (192‚Üí24)\n",
    "# (B, 24, 28, 28)\n",
    "#     ‚Üì + Skip (si dimensiones coinciden)\n",
    "# Output: (B, 24, 28, 28)\n",
    "```\n",
    "\n",
    "### ‚ö° **Componentes Clave:**\n",
    "\n",
    "1. **Expansi√≥n 1x1**: \n",
    "   - Aumenta canales para mejor representaci√≥n\n",
    "   - Activaci√≥n: Swish/SiLU (mejor que ReLU)\n",
    "\n",
    "2. **Depthwise Convolution**: \n",
    "   - Captura patrones espaciales\n",
    "   - Eficiencia computacional extrema\n",
    "\n",
    "3. **Squeeze-and-Excitation**: \n",
    "   - Atenci√≥n en canales importantes\n",
    "   - Mejora significativa en accuracy\n",
    "\n",
    "4. **Proyecci√≥n 1x1**: \n",
    "   - Reduce dimensionalidad\n",
    "   - Sin activaci√≥n (preserva informaci√≥n)\n",
    "\n",
    "5. **Skip Connection**: \n",
    "   - Evita degradaci√≥n del gradiente\n",
    "   - Permite redes m√°s profundas\n",
    "\n",
    "### üéØ **Configuraciones por Etapa:**\n",
    "\n",
    "| Etapa | Output Ch | Kernel | Stride | Expand | Repeticiones |\n",
    "|-------|-----------|--------|--------|---------|-------------|\n",
    "| 1     | 16        | 3      | 1      | 1       | 1          |\n",
    "| 2     | 24        | 3      | 2      | 6       | 2          |\n",
    "| 3     | 40        | 5      | 2      | 6       | 2          |\n",
    "| 4     | 80        | 3      | 2      | 6       | 3          |\n",
    "| 5     | 112       | 5      | 1      | 6       | 3          |\n",
    "| 6     | 192       | 5      | 2      | 6       | 4          |\n",
    "| 7     | 320       | 3      | 1      | 6       | 1          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61bca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, stride=1,\n",
    "                 expand_ratio=6, se_ratio=0.25, drop_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.use_res = (stride == 1 and in_ch == out_ch)\n",
    "        self.drop_rate = drop_rate\n",
    "        mid_ch = in_ch if expand_ratio == 1 else in_ch * expand_ratio\n",
    "        \n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            layers += [\n",
    "                nn.Conv2d(in_ch, mid_ch, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(mid_ch),\n",
    "                nn.SiLU(inplace=True)\n",
    "            ]\n",
    "        \n",
    "        layers += [\n",
    "            nn.Conv2d(mid_ch, mid_ch, kernel_size, stride, kernel_size//2, groups=mid_ch, bias=False),\n",
    "            nn.BatchNorm2d(mid_ch),\n",
    "            nn.SiLU(inplace=True)\n",
    "        ]\n",
    "        \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.se = SEModule(mid_ch, reduction=int(1/se_ratio))\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(mid_ch, out_ch, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        y = self.features(x)\n",
    "        y = self.se(y)\n",
    "        y = self.project(y)\n",
    "        if self.use_res:\n",
    "            y = y + identity\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1b6b9",
   "metadata": {},
   "source": [
    "\n",
    "## 4. EfficientNet-B0 Mini (Educativo)\n",
    "\n",
    "Implementaci√≥n reducida de EfficientNet-B0, √∫til para fines educativos.  \n",
    "No incluye pesos preentrenados, pero mantiene la estructura principal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183b60f",
   "metadata": {},
   "source": [
    "### üèÜ **Innovaciones Clave de EfficientNet**\n",
    "\n",
    "#### **1. Neural Architecture Search (NAS)**\n",
    "- **Automatizaci√≥n**: La arquitectura base se dise√±√≥ usando b√∫squeda autom√°tica\n",
    "- **Optimizaci√≥n**: Balance √≥ptimo entre accuracy y eficiencia\n",
    "- **Resultado**: EfficientNet-B0 como arquitectura base optimal\n",
    "\n",
    "#### **2. Compound Scaling Method**\n",
    "```python\n",
    "# Escalado tradicional (problem√°tico):\n",
    "# Solo profundidad: ResNet-50 ‚Üí ResNet-101 ‚Üí ResNet-152\n",
    "# Solo anchura: M√°s canales por capa\n",
    "# Solo resoluci√≥n: Im√°genes m√°s grandes\n",
    "\n",
    "# Escalado compuesto (EfficientNet):\n",
    "depth = Œ±^œÜ     # Œ± = 1.2\n",
    "width = Œ≤^œÜ     # Œ≤ = 1.1  \n",
    "resolution = Œ≥^œÜ # Œ≥ = 1.15\n",
    "# Restricci√≥n: Œ± ¬∑ Œ≤¬≤ ¬∑ Œ≥¬≤ ‚âà 2\n",
    "```\n",
    "\n",
    "#### **3. Comparaci√≥n con Otras Arquitecturas**\n",
    "\n",
    "| Modelo | Par√°metros | FLOPs | Top-1 Accuracy |\n",
    "|--------|------------|-------|---------------|\n",
    "| ResNet-50 | 25.6M | 4.1B | 76.0% |\n",
    "| ResNet-152 | 60.2M | 11.6B | 77.8% |\n",
    "| DenseNet-264 | 33.3M | 5.8B | 77.9% |\n",
    "| **EfficientNet-B0** | **5.3M** | **0.39B** | **77.1%** |\n",
    "| **EfficientNet-B7** | **66M** | **37B** | **84.4%** |\n",
    "\n",
    "### üî¨ **An√°lisis de Eficiencia**\n",
    "\n",
    "#### **Memoria y Computaci√≥n:**\n",
    "```python\n",
    "# Comparaci√≥n de operaciones (ejemplo 224x224):\n",
    "Traditional Conv 3x3: O(H√óW√óCin√óCout√ó9)\n",
    "Depthwise + Pointwise: O(H√óW√óCin√ó9 + H√óW√óCin√óCout)\n",
    "\n",
    "# Para 192 canales entrada/salida:\n",
    "Traditional: 224√ó224√ó192√ó192√ó9 = 52.6B ops\n",
    "MBConv: 224√ó224√ó192√ó9 + 224√ó224√ó192√ó192 = 0.87B ops\n",
    "# ¬°60x m√°s eficiente!\n",
    "```\n",
    "\n",
    "#### **Escalado Inteligente:**\n",
    "- **Œ± (profundidad)**: M√°s capas ‚Üí mejor representaci√≥n\n",
    "- **Œ≤ (anchura)**: M√°s canales ‚Üí mayor capacidad  \n",
    "- **Œ≥ (resoluci√≥n)**: Im√°genes grandes ‚Üí m√°s detalles finos\n",
    "- **Balance**: Los tres factores se complementan exponencialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc58a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EfficientNetB0Mini(nn.Module):\n",
    "    def __init__(self, num_classes=1000, drop_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        cfg = [\n",
    "            (16, 3, 1, 1, 1),\n",
    "            (24, 3, 2, 6, 2),\n",
    "            (40, 5, 2, 6, 2),\n",
    "            (80, 3, 2, 6, 3),\n",
    "            (112, 5, 1, 6, 3),\n",
    "            (192, 5, 2, 6, 4),\n",
    "            (320, 3, 1, 6, 1)\n",
    "        ]\n",
    "        \n",
    "        blocks = []\n",
    "        in_ch = 32\n",
    "        for out_ch, k, s, exp, reps in cfg:\n",
    "            for i in range(reps):\n",
    "                stride = s if i == 0 else 1\n",
    "                blocks.append(MBConv(in_ch, out_ch, kernel_size=k, stride=stride, expand_ratio=exp))\n",
    "                in_ch = out_ch\n",
    "        \n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 1280, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(1280, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a68c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = EfficientNetB0Mini().to(device)\n",
    "print(\"Modelo creado en\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ba778",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Inferencia\n",
    "\n",
    "Ejemplo de inferencia con una imagen de entrada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform_infer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img_path = \"foto.jpg\"\n",
    "if Path(img_path).exists():\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform_infer(img).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = logits.softmax(dim=1)\n",
    "    print(\"Shape de salida:\", probs.shape)\n",
    "else:\n",
    "    print(\"Coloca una imagen llamada 'foto.jpg' en el directorio actual.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sis-421-SSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
