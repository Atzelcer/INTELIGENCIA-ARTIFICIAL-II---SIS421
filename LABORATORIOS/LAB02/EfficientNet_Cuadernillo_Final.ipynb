{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905da27d",
   "metadata": {},
   "source": [
    "\n",
    "# Cuadernillo: EfficientNet (Teoría + Implementación en PyTorch)\n",
    "\n",
    "Este cuadernillo combina la explicación teórica de EfficientNet con una implementación educativa en PyTorch de la versión B0 (modelo base).\n",
    "\n",
    "## Contenido:\n",
    "- Introducción a EfficientNet y el escalado compuesto.\n",
    "- Arquitectura de EfficientNet-B0.\n",
    "- Implementación desde cero del bloque MBConv con Squeeze-and-Excitation (SE).\n",
    "- Construcción de EfficientNet-B0 mini.\n",
    "- Ejemplo de inferencia.\n",
    "- Ejemplo de fine-tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcfd922",
   "metadata": {},
   "source": [
    "## 1. Introducción a EfficientNet\n",
    "\n",
    "EfficientNet es una familia de redes neuronales convolucionales que introduce el concepto de **escalado compuesto** para mejorar el rendimiento y la eficiencia. La idea es escalar de forma balanceada tres dimensiones de la red:\n",
    "\n",
    "- **Profundidad (d):** Número de capas.\n",
    "- **Anchura (w):** Número de canales en cada capa.\n",
    "- **Resolución (r):** Tamaño de la imagen de entrada.\n",
    "\n",
    "### 🔬 Escalado Compuesto\n",
    "\n",
    "El escalado se controla con un factor φ (phi) y tres coeficientes α, β, γ:\n",
    "\n",
    "```\n",
    "depth = α^φ\n",
    "width = β^φ  \n",
    "resolution = γ^φ\n",
    "```\n",
    "\n",
    "**Restricción:** α · β² · γ² ≈ 2, donde α ≥ 1, β ≥ 1, γ ≥ 1\n",
    "\n",
    "### 🎯 Ventajas de EfficientNet:\n",
    "\n",
    "1. **Eficiencia computacional**: Mejor accuracy con menos parámetros\n",
    "2. **Escalado balanceado**: No solo aumenta una dimensión\n",
    "3. **Transferible**: Funciona bien en diferentes tareas\n",
    "4. **Arquitectura optimizada**: Basada en Neural Architecture Search (NAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f751228",
   "metadata": {},
   "source": [
    "## Arquitectura de EfficientNet\n",
    "\n",
    "La siguiente imagen muestra la arquitectura y funcionamiento de EfficientNet:\n",
    "\n",
    "![EfficientNet Architecture](IMAGE.png)\n",
    "\n",
    "*Figura: Arquitectura y escalado compuesto de EfficientNet mostrando cómo se balancean las dimensiones de profundidad, anchura y resolución.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1da8b2",
   "metadata": {},
   "source": [
    "## 📊 Funcionamiento Detallado del Modelo EfficientNet\n",
    "\n",
    "### 🏗️ **Arquitectura General**\n",
    "\n",
    "EfficientNet sigue esta estructura principal:\n",
    "\n",
    "```\n",
    "Input Image → Stem → MBConv Blocks → Head → Output\n",
    "```\n",
    "\n",
    "### 🔍 **1. Stem (Inicio)**\n",
    "- **Función**: Preprocesamiento inicial de la imagen\n",
    "- **Operación**: Convolución 3x3 con stride=2\n",
    "- **Salida**: Reduce resolución a la mitad, extrae características básicas\n",
    "- **Canales**: RGB (3) → 32 características\n",
    "\n",
    "### 🧱 **2. Bloques MBConv (Corazón del modelo)**\n",
    "\n",
    "Los bloques MBConv son la innovación clave. Cada bloque realiza:\n",
    "\n",
    "#### **Paso 1: Expansión (1x1 Conv)**\n",
    "```python\n",
    "# Si expand_ratio > 1\n",
    "channels: in_ch → in_ch * expand_ratio\n",
    "# Ejemplo: 32 → 192 canales (expand_ratio=6)\n",
    "```\n",
    "\n",
    "#### **Paso 2: Depthwise Convolution**\n",
    "```python\n",
    "# Convolución por grupos (cada canal por separado)\n",
    "- Reduce parámetros significativamente\n",
    "- Captura patrones espaciales por canal\n",
    "- Kernel: 3x3 o 5x5\n",
    "```\n",
    "\n",
    "#### **Paso 3: Squeeze-and-Excitation (SE)**\n",
    "```python\n",
    "# Recalibración de canales\n",
    "Global Average Pool → FC → ReLU → FC → Sigmoid → Multiply\n",
    "```\n",
    "\n",
    "#### **Paso 4: Proyección (1x1 Conv)**\n",
    "```python\n",
    "# Reducción de canales\n",
    "channels: expanded → out_ch\n",
    "# Ejemplo: 192 → 40 canales\n",
    "```\n",
    "\n",
    "#### **Paso 5: Skip Connection**\n",
    "```python\n",
    "if stride == 1 and in_ch == out_ch:\n",
    "    output = projection + input  # Residual connection\n",
    "```\n",
    "\n",
    "### 🎯 **3. Head (Final)**\n",
    "- **Global Average Pooling**: Convierte feature maps a vector\n",
    "- **Dropout**: Regularización para evitar overfitting  \n",
    "- **Linear**: Clasificación final (1000 clases en ImageNet)\n",
    "\n",
    "### ⚡ **Flujo de Datos Completo**\n",
    "\n",
    "```\n",
    "Imagen (224x224x3)\n",
    "    ↓ Stem Conv3x3\n",
    "Feature Maps (112x112x32)\n",
    "    ↓ MBConv Stage 1 (16 canales)\n",
    "Feature Maps (112x112x16)\n",
    "    ↓ MBConv Stage 2 (24 canales)\n",
    "Feature Maps (56x56x24)\n",
    "    ↓ MBConv Stage 3 (40 canales)\n",
    "Feature Maps (28x28x40)\n",
    "    ↓ MBConv Stage 4 (80 canales)\n",
    "Feature Maps (14x14x80)\n",
    "    ↓ MBConv Stage 5 (112 canales)\n",
    "Feature Maps (14x14x112)\n",
    "    ↓ MBConv Stage 6 (192 canales)\n",
    "Feature Maps (7x7x192)\n",
    "    ↓ MBConv Stage 7 (320 canales)\n",
    "Feature Maps (7x7x320)\n",
    "    ↓ Head Conv1x1\n",
    "Feature Maps (7x7x1280)\n",
    "    ↓ Global Average Pool\n",
    "Vector (1280)\n",
    "    ↓ Dropout + Linear\n",
    "Logits (1000 clases)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f9aa8",
   "metadata": {},
   "source": [
    "## 2. Bloque Squeeze-and-Excitation (SE) - Explicación Detallada\n",
    "\n",
    "### 🧠 **¿Qué problema resuelve SE?**\n",
    "\n",
    "Las redes convolucionales tradicionales tratan todos los canales por igual. Sin embargo, **algunos canales contienen información más relevante que otros**. El bloque SE aprende a **recalibrar automáticamente** la importancia de cada canal.\n",
    "\n",
    "### ⚙️ **Funcionamiento paso a paso:**\n",
    "\n",
    "#### **Paso 1: Squeeze (Compresión) 🗜️**\n",
    "```python\n",
    "# Global Average Pooling\n",
    "input: (Batch, Channels, Height, Width)\n",
    "output: (Batch, Channels, 1, 1)\n",
    "```\n",
    "- **Función**: Convierte cada mapa de características 2D en un único valor\n",
    "- **Resultado**: Captura la \"esencia\" global de cada canal\n",
    "- **Matemáticamente**: `z_c = (1/H*W) * Σ(x_c(i,j))`\n",
    "\n",
    "#### **Paso 2: Excitation (Activación) ⚡**\n",
    "```python\n",
    "# Dos capas completamente conectadas\n",
    "FC1: channels → channels//reduction  # Compresión\n",
    "ReLU: Activación no lineal\n",
    "FC2: channels//reduction → channels   # Expansión  \n",
    "Sigmoid: Normalización [0,1]\n",
    "```\n",
    "- **Función**: Aprende las interdependencias entre canales\n",
    "- **Reduction**: Típicamente 4 o 16 (reduce parámetros)\n",
    "- **Sigmoid**: Asegura que los pesos estén entre 0 y 1\n",
    "\n",
    "#### **Paso 3: Scale (Reescalado) 📏**\n",
    "```python\n",
    "# Multiplicación elemento por elemento\n",
    "output = input * se_weights.unsqueeze(-1).unsqueeze(-1)\n",
    "```\n",
    "- **Función**: Aplica los pesos aprendidos a cada canal\n",
    "- **Resultado**: Canales importantes se amplifican, irrelevantes se atenúan\n",
    "\n",
    "### 🎯 **Ejemplo Práctico:**\n",
    "Si tenemos una imagen de un gato:\n",
    "- **Canales de bordes**: Peso alto (importante para detectar forma)\n",
    "- **Canales de textura**: Peso medio (útil para pelaje)\n",
    "- **Canales de ruido**: Peso bajo (información irrelevante)\n",
    "\n",
    "### 📈 **Beneficios:**\n",
    "1. **Mejora accuracy** sin costo computacional significativo\n",
    "2. **Atención automática** en características relevantes  \n",
    "3. **Fácil integración** en cualquier arquitectura CNN\n",
    "4. **Pocos parámetros adicionales** (~2% del total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bac894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        hidden = max(1, channels // reduction)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, hidden, kernel_size=1),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(hidden, channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        w = self.pool(x)\n",
    "        w = self.fc(w)\n",
    "        return x * w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34fce9",
   "metadata": {},
   "source": [
    "## 3. Bloque MBConv (Mobile Inverted Bottleneck) - Análisis Completo\n",
    "\n",
    "### 🏗️ **Filosofía del Diseño**\n",
    "\n",
    "El bloque MBConv invierte la filosofía tradicional de los bottlenecks:\n",
    "- **Bottleneck tradicional**: Ancho → Estrecho → Ancho\n",
    "- **Inverted Bottleneck**: Estrecho → Ancho → Estrecho\n",
    "\n",
    "### 🔄 **Arquitectura Detallada:**\n",
    "\n",
    "```\n",
    "Input (low-dim) → Expand (high-dim) → Filter → Compress (low-dim) → Output\n",
    "```\n",
    "\n",
    "#### **🚀 Ventaja 1: Expansión**\n",
    "```python\n",
    "# Expansión 1x1 (si expand_ratio > 1)\n",
    "if expand_ratio != 1:\n",
    "    channels: in_ch → in_ch * expand_ratio\n",
    "```\n",
    "- **Por qué**: Las convoluciones depthwise funcionan mejor con más canales\n",
    "- **Ejemplo**: 32 canales → 192 canales (expand_ratio=6)\n",
    "- **Beneficio**: Más \"espacio\" para aprender características complejas\n",
    "\n",
    "#### **🎯 Ventaja 2: Depthwise Convolution**\n",
    "```python\n",
    "# Convolución por grupos (cada canal independiente)\n",
    "groups = input_channels  # Cada canal se procesa por separado\n",
    "```\n",
    "\n",
    "**Comparación de parámetros:**\n",
    "```python\n",
    "# Convolución tradicional 3x3:\n",
    "params_traditional = in_ch * out_ch * 3 * 3\n",
    "# Ejemplo: 192 * 192 * 9 = 331,776 parámetros\n",
    "\n",
    "# Depthwise + Pointwise:\n",
    "params_depthwise = in_ch * 3 * 3 + in_ch * out_ch\n",
    "# Ejemplo: 192 * 9 + 192 * 32 = 1,728 + 6,144 = 7,872 parámetros\n",
    "# ¡42x menos parámetros!\n",
    "```\n",
    "\n",
    "#### **🧠 Ventaja 3: Información Preservada**\n",
    "La conexión residual preserva información:\n",
    "```python\n",
    "if stride == 1 and in_ch == out_ch:\n",
    "    output = processed_input + input  # Skip connection\n",
    "```\n",
    "\n",
    "### 📊 **Flujo Completo de un MBConv:**\n",
    "\n",
    "```python\n",
    "# Entrada: (B, 32, 56, 56)\n",
    "#     ↓ Expand 1x1 (32→192)\n",
    "# (B, 192, 56, 56)\n",
    "#     ↓ Depthwise 3x3\n",
    "# (B, 192, 28, 28)  # Si stride=2\n",
    "#     ↓ SE Module (recalibración)\n",
    "# (B, 192, 28, 28)\n",
    "#     ↓ Project 1x1 (192→24)\n",
    "# (B, 24, 28, 28)\n",
    "#     ↓ + Skip (si dimensiones coinciden)\n",
    "# Output: (B, 24, 28, 28)\n",
    "```\n",
    "\n",
    "### ⚡ **Componentes Clave:**\n",
    "\n",
    "1. **Expansión 1x1**: \n",
    "   - Aumenta canales para mejor representación\n",
    "   - Activación: Swish/SiLU (mejor que ReLU)\n",
    "\n",
    "2. **Depthwise Convolution**: \n",
    "   - Captura patrones espaciales\n",
    "   - Eficiencia computacional extrema\n",
    "\n",
    "3. **Squeeze-and-Excitation**: \n",
    "   - Atención en canales importantes\n",
    "   - Mejora significativa en accuracy\n",
    "\n",
    "4. **Proyección 1x1**: \n",
    "   - Reduce dimensionalidad\n",
    "   - Sin activación (preserva información)\n",
    "\n",
    "5. **Skip Connection**: \n",
    "   - Evita degradación del gradiente\n",
    "   - Permite redes más profundas\n",
    "\n",
    "### 🎯 **Configuraciones por Etapa:**\n",
    "\n",
    "| Etapa | Output Ch | Kernel | Stride | Expand | Repeticiones |\n",
    "|-------|-----------|--------|--------|---------|-------------|\n",
    "| 1     | 16        | 3      | 1      | 1       | 1          |\n",
    "| 2     | 24        | 3      | 2      | 6       | 2          |\n",
    "| 3     | 40        | 5      | 2      | 6       | 2          |\n",
    "| 4     | 80        | 3      | 2      | 6       | 3          |\n",
    "| 5     | 112       | 5      | 1      | 6       | 3          |\n",
    "| 6     | 192       | 5      | 2      | 6       | 4          |\n",
    "| 7     | 320       | 3      | 1      | 6       | 1          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61bca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, stride=1,\n",
    "                 expand_ratio=6, se_ratio=0.25, drop_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.use_res = (stride == 1 and in_ch == out_ch)\n",
    "        self.drop_rate = drop_rate\n",
    "        mid_ch = in_ch if expand_ratio == 1 else in_ch * expand_ratio\n",
    "        \n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            layers += [\n",
    "                nn.Conv2d(in_ch, mid_ch, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(mid_ch),\n",
    "                nn.SiLU(inplace=True)\n",
    "            ]\n",
    "        \n",
    "        layers += [\n",
    "            nn.Conv2d(mid_ch, mid_ch, kernel_size, stride, kernel_size//2, groups=mid_ch, bias=False),\n",
    "            nn.BatchNorm2d(mid_ch),\n",
    "            nn.SiLU(inplace=True)\n",
    "        ]\n",
    "        \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.se = SEModule(mid_ch, reduction=int(1/se_ratio))\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(mid_ch, out_ch, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        y = self.features(x)\n",
    "        y = self.se(y)\n",
    "        y = self.project(y)\n",
    "        if self.use_res:\n",
    "            y = y + identity\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1b6b9",
   "metadata": {},
   "source": [
    "\n",
    "## 4. EfficientNet-B0 Mini (Educativo)\n",
    "\n",
    "Implementación reducida de EfficientNet-B0, útil para fines educativos.  \n",
    "No incluye pesos preentrenados, pero mantiene la estructura principal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183b60f",
   "metadata": {},
   "source": [
    "### 🏆 **Innovaciones Clave de EfficientNet**\n",
    "\n",
    "#### **1. Neural Architecture Search (NAS)**\n",
    "- **Automatización**: La arquitectura base se diseñó usando búsqueda automática\n",
    "- **Optimización**: Balance óptimo entre accuracy y eficiencia\n",
    "- **Resultado**: EfficientNet-B0 como arquitectura base optimal\n",
    "\n",
    "#### **2. Compound Scaling Method**\n",
    "```python\n",
    "# Escalado tradicional (problemático):\n",
    "# Solo profundidad: ResNet-50 → ResNet-101 → ResNet-152\n",
    "# Solo anchura: Más canales por capa\n",
    "# Solo resolución: Imágenes más grandes\n",
    "\n",
    "# Escalado compuesto (EfficientNet):\n",
    "depth = α^φ     # α = 1.2\n",
    "width = β^φ     # β = 1.1  \n",
    "resolution = γ^φ # γ = 1.15\n",
    "# Restricción: α · β² · γ² ≈ 2\n",
    "```\n",
    "\n",
    "#### **3. Comparación con Otras Arquitecturas**\n",
    "\n",
    "| Modelo | Parámetros | FLOPs | Top-1 Accuracy |\n",
    "|--------|------------|-------|---------------|\n",
    "| ResNet-50 | 25.6M | 4.1B | 76.0% |\n",
    "| ResNet-152 | 60.2M | 11.6B | 77.8% |\n",
    "| DenseNet-264 | 33.3M | 5.8B | 77.9% |\n",
    "| **EfficientNet-B0** | **5.3M** | **0.39B** | **77.1%** |\n",
    "| **EfficientNet-B7** | **66M** | **37B** | **84.4%** |\n",
    "\n",
    "### 🔬 **Análisis de Eficiencia**\n",
    "\n",
    "#### **Memoria y Computación:**\n",
    "```python\n",
    "# Comparación de operaciones (ejemplo 224x224):\n",
    "Traditional Conv 3x3: O(H×W×Cin×Cout×9)\n",
    "Depthwise + Pointwise: O(H×W×Cin×9 + H×W×Cin×Cout)\n",
    "\n",
    "# Para 192 canales entrada/salida:\n",
    "Traditional: 224×224×192×192×9 = 52.6B ops\n",
    "MBConv: 224×224×192×9 + 224×224×192×192 = 0.87B ops\n",
    "# ¡60x más eficiente!\n",
    "```\n",
    "\n",
    "#### **Escalado Inteligente:**\n",
    "- **α (profundidad)**: Más capas → mejor representación\n",
    "- **β (anchura)**: Más canales → mayor capacidad  \n",
    "- **γ (resolución)**: Imágenes grandes → más detalles finos\n",
    "- **Balance**: Los tres factores se complementan exponencialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc58a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EfficientNetB0Mini(nn.Module):\n",
    "    def __init__(self, num_classes=1000, drop_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        cfg = [\n",
    "            (16, 3, 1, 1, 1),\n",
    "            (24, 3, 2, 6, 2),\n",
    "            (40, 5, 2, 6, 2),\n",
    "            (80, 3, 2, 6, 3),\n",
    "            (112, 5, 1, 6, 3),\n",
    "            (192, 5, 2, 6, 4),\n",
    "            (320, 3, 1, 6, 1)\n",
    "        ]\n",
    "        \n",
    "        blocks = []\n",
    "        in_ch = 32\n",
    "        for out_ch, k, s, exp, reps in cfg:\n",
    "            for i in range(reps):\n",
    "                stride = s if i == 0 else 1\n",
    "                blocks.append(MBConv(in_ch, out_ch, kernel_size=k, stride=stride, expand_ratio=exp))\n",
    "                in_ch = out_ch\n",
    "        \n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 1280, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(1280, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a68c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = EfficientNetB0Mini().to(device)\n",
    "print(\"Modelo creado en\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ba778",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Inferencia\n",
    "\n",
    "Ejemplo de inferencia con una imagen de entrada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform_infer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img_path = \"foto.jpg\"\n",
    "if Path(img_path).exists():\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform_infer(img).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = logits.softmax(dim=1)\n",
    "    print(\"Shape de salida:\", probs.shape)\n",
    "else:\n",
    "    print(\"Coloca una imagen llamada 'foto.jpg' en el directorio actual.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sis-421-SSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
